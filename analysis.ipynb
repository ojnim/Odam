{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import nltk\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from processing import accessfile, one, Word_count, table_count, dataFrame_create, distance_between_nouns, distance_between_DET, Word_verbtype_count, tagging, tagging_dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Odam0829.xml'\n",
    "title_list1 = ['AFFlores Teneraca1','ELAN 01','ELAN 02','ELAN 03','ELAN 04','ELAN 11','ELAN 14','ELAN 15']\n",
    "title_list2 = [\"Gu a'lhich ja'tkam\",\"Gu bhiich kulierdam\",\"Gu Bib\",\"Gu chio'ñ gux chuk t+t+'kam\",\"Gu J+b++lh Gio Gu Tanoolh\",\"Gu joob nat bh+m gu tai\",\"Gu Kooxi'\"]\n",
    "title_list3 = [\"Gu mamra'n nat mai' ja iobu\",\"Gu naks+r\",\"gu tur\",\"Jix Chuumñigam (AD &amp; GG 2013: 58)\",\"Nat tum sur\",'Historia de Charcos','Teneraca 5 Familia','Teneraca 7 Varios Cuentos']\n",
    "text_list = title_list1 + title_list2 + title_list3\n",
    "title_tagging = ['AFFlores TAGGING','Gu joob TAGGING']\n",
    "body, namespace = accessfile(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DET')\n",
    "DET_list = []\n",
    "for i in range(len(text_list)):\n",
    "    text = one(body, namespace,text_list[i])\n",
    "    Word_noun = Word_count(text, namespace,\"Interlin Word Gloss es\",'DET')\n",
    "    DET_list.append(Word_noun)\n",
    "    print(text_list[i], ':', Word_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Noun')\n",
    "sus_list = []\n",
    "for i in range(len(text_list)):\n",
    "    text = one(body, namespace,text_list[i])\n",
    "    Word_noun = Word_count(text, namespace,\"Interlin Word POS\",'sus')\n",
    "    sus_list.append(Word_noun)\n",
    "    print(text_list[i], ':', Word_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1pl, 2pl')\n",
    "pro_list = []\n",
    "#minus the number of pronoun\n",
    "#Interlin Morpheme Gloss es: 1pl, 2pl\n",
    "for i in range(len(text_list)):\n",
    "    text = one(body, namespace,text_list[i])\n",
    "    Morph_pro = table_count(text, namespace,'Interlin Morpheme Gloss es', ['1pl', '2pl'])\n",
    "    pro_list.append(Morph_pro)\n",
    "    print(text_list[i], ':', Morph_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_list = []\n",
    "for i in range(len(text_list)):\n",
    "    text = one(body, namespace,text_list[i])\n",
    "    Word_verb = Word_count(text, namespace,\"Interlin Word POS\",'v')\n",
    "    Word_cop = Word_count(text, namespace,\"Interlin Word POS\",'cop')\n",
    "    total = Word_verb + Word_cop\n",
    "    verb_list.append(total)\n",
    "    print(text_list[i], ':', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_type_list = []\n",
    "for i in range(len(text_list)):\n",
    "    #vi, vt, cop, v.ctrl, vb, v, Verb\n",
    "    text = one(body, namespace,text_list[i])\n",
    "    Word_verbtype = Word_verbtype_count(text, namespace,\"Interlin Word POS\")\n",
    "    total = Word_verbtype[0]+Word_verbtype[1]*2+Word_verbtype[2]+Word_verbtype[3]*2+Word_verbtype[4]*3+Word_verbtype[5]+Word_verbtype[6]-pro_list[i]\n",
    "    verb_type_list.append(total)\n",
    "    print(text_list[i], ':', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_list = []\n",
    "for i in range(len(text_list)):\n",
    "    text = one(body, namespace,text_list[i])\n",
    "    Morph_Post = table_count(text, namespace,'Interlin Morpheme POS', ['post'])\n",
    "    post_list.append(Morph_Post)\n",
    "    print(text_list[i], ':', Morph_Post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_noun_list = [np.log(e) for e in sus_list]\n",
    "log_verb_list = [np.log(e) for e in verb_list]\n",
    "\n",
    "plt.plot(text_list,log_noun_list,label='Nouns')\n",
    "plt.plot(text_list,log_verb_list,label='Verbs')\n",
    "plt.xticks(fontsize=8, rotation=90)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(text_list)) \n",
    "width = 0.35 \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, sus_list, width, label='Noun')\n",
    "rects2 = ax.bar(x + width/2, verb_list, width, label='Verb')\n",
    "\n",
    "ax.set_xlabel('Text')\n",
    "ax.set_title('Sus and Verb Plot')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(text_list)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.xticks(fontsize=8, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(text_list)) \n",
    "width = 0.35 \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, DET_list, width, label='DET')\n",
    "rects2 = ax.bar(x + width/2, sus_list, width, label='sus')\n",
    "\n",
    "ax.set_xlabel('Text')\n",
    "ax.set_ylabel('count')\n",
    "ax.set_title('DET and sus Plot')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(text_list)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.xticks(fontsize=8, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(text_list)) \n",
    "width = 0.35 \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, sus_list, width, label='Noun')\n",
    "rects2 = ax.bar(x + width/2, verb_type_list, width, label='ExpNoun')\n",
    "\n",
    "ax.set_xlabel('Text')\n",
    "ax.set_ylabel('Diff')\n",
    "ax.set_title('Noun vs ExpNoun')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(text_list)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.xticks(fontsize=8, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_text_list = []\n",
    "for i in range(len(text_list)):\n",
    "    text = one(body, namespace,text_list[i])\n",
    "    dist = distance_between_nouns(text, namespace)\n",
    "    dist_text_list += dist\n",
    "    print(text_list[i], ':', dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def remove_outliers(data):\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return [x for x in data if lower_bound <= x <= upper_bound]\n",
    "\n",
    "filtered_dist = remove_outliers(dist_text_list)\n",
    "\n",
    "# Count the frequency of each element in the filtered list\n",
    "counter = Counter(filtered_dist)\n",
    "\n",
    "# Separate the keys and values for plotting\n",
    "elements = list(counter.keys())\n",
    "frequencies = list(counter.values())\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(elements, frequencies, color='skyblue')\n",
    "plt.xlabel('Elements')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Elements in the List (Outliers Removed)')\n",
    "plt.xticks(elements)  # Set x-ticks to the unique elements\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
